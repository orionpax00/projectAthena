{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention_ntm_dnc.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe2ocTS5xziD",
        "colab_type": "text"
      },
      "source": [
        "# Attension Mechanism \n",
        "\n",
        "Attension Mechanism ðŸŽ¯ as the name indicated is similiar to the it actual Vocab meaning that is *the action of dealing with or taking special care of someone or something*. In deep learning problems where model have to check for the state before the currents state of the it the problem of not remembering the complete information from the initial step when the number of steps are too many, similiar in image recognition there are some areas of image that are more important then the rest so, paying more attention to them will effect the results significantly, most common example are Neural machine translation and Image Captioning.\n",
        "\n",
        "### Lets Take One example from each category...\n",
        "* ### Image Captioning\n",
        "![dog with a ball](https://cdn.shopify.com/s/files/1/0316/8657/articles/Playing_Fetch_with_Cute_Beagle_Dog_1200x628.jpg?v=1524173955)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdaXzBsBxsyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}